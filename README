ORTHOGRAPH: Orthology prediction using a Graph-based, Reciprocal Approach with
Profile Hidden Markov models

SYSTEM REQUIREMENTS
===================

Orthograph requires the following software packages to be installed on the
system. The whole package was tested and works with these versions, and newer
versions should be no problem. Downwards compatibility (i.e., older versions)
has not been tested. Should be fine, too, but be wary with MAFFT, its developers
change or drop features frequently across versions.

You need a database backend, either SQLite (the default) or MySQL. If you don't
know which one to pick, use SQLite. It's easier to install and use, but doesn't
have the capabilities for a centralized server-client setup. In grid computing
environments, this is an advantage since no network connections are required,
but the database is a flat file on the hard drive.

Package      | Version | Download from
:------------|:--------|:-----------------------------------------------------------
Perl         | 5.14    | http://www.perl.org
SQLite       | 3.8.2   | http://sqlite.org/download.html
MySQL        | 5.6.17  | http://dev.mysql.com/downloads/mysql/
MAFFT        | 7.023b  | http://mafft.cbrc.jp/alignment/software/
HMMer        | 3.1b1   | http://hmmer.janelia.org/software/
NCBI BLAST+  | 2.2.28+ | ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/
Exonerate    | 2.2.0   | http://www.ebi.ac.uk/~guy/exonerate/

Make sure you get the correct versions for your operating system (most packages
are provided as 32 bit and 64 bit versions).

Don't worry about your Perl version if you run a reasonably recent Linux or
UNIX system, such as Mac OS X, but see [here] [1] and [there] [2] if you are
trying to install the required packages on a Windows system under Cygwin (or
natively, for that matter). You might run into problems getting the MySQL
driver, HMMer3 and Exonerate to work. Really, don't use Windows. 

Make sure you have the database interface module DBI for your Perl version as
well as the proper database driver for your database engine of choice
(DBD::mysql or DBD::SQLite)

If you get an error like "Can't locate Some/Module.pm in @INC", you need to
update your Perl installation; see REQUIRED PERL MODULES for more information.

DATA REQUIREMENTS
=================

Orthograph is an orthology prediction pipeline that attempts to map transcript
sequences to known orthologous groups. It is not meant to infer orthology de
novo among genomes or transcriptomes, but relies on the orthology information in
pre-defined sets. Because of this requirement, it is essential that your input
data conforms to some data standards as listed below.

a) The clusters of orthologous groups (COGs). It consists of a Fasta file that
contains at least one sequence per selected COG. If you get your COGs from
OrthoDB [1] (recommended), this is the case. In an OrthoDB file, each sequence
header contains a COG ID, in the case of OrthoDB version 5, it is something
like:

	>APISU:gmsk09 ACYPI007477 EOG500005 ACYPI007477-PA origin:RefSeq

The 'EOG500005' field is the COG ID. The sequence header must also contain an
unambiguous sequence ID. In the above example, it is the fourth field, i.e.,
'ACYPI007477'. 

b) The official gene set (OGS) for each of the taxa that are present in the
ortholog set, i.e., contributed sequences to the COGs. The sequences for a
single taxon must be in Fasta format, and all (!) sequences of this taxon that
occur in the COGs must be in the OGS database as well. Their sequence identifier
must be unambiguously identical to the sequence ID in the Fasta file from
OrthoDB. For example, this would be the related sequence for Acyrthosiphon pisum
from the OGS:

	>ACYPI007477-PA origin:RefSeq

The OGS must be present as amino acid sequences, and may be present as
nucleotide sequences. If the latter is missing, no nucleotide sequences can be
output for the reference taxa. The sequence identifiers of corresponding
nucleotide and amino acid sequences must be identical.

The helper script make-ogs-corresponding.pl is provided that uses Exonerate to
generate 100% corresponding amino acid and nucleotide sequences for the OGS. It
only requires that the identifiers are unambiguously identical. You can call it
like this:

	perl make-ogs-corresponding.pl [OPTIONS] PEPTIDEFILE CDSFILE

Provide the OGS on amino acid level as PEPTIDEFILE and on nucleotide level as
CDSFILE. A list of options is printed when you call the script without arguments
or with the -h option.

QUICKSTART
==========

For a fast start into analysis using Orthograph, follow these steps. They
assume that all required software packages are installed and work. 


## 1. These conventions are used throughout this documentation:

	$ some_command

This means you should enter some_command at the shell prompt. The `$` sigil is
not part of the command.


## 2. Create a config file. 

Make a copy of the supplied config file orthograph.conf.example and rename this
copy to orthograph.conf. Edit it. The file is commented to help you start off.
Most options are self-explanatory. 

For now, it is sufficient to supply the database settings (for SQLite: path to
the database file; for MySQL: database, username, password). If you don't know
how to create a MySQL user and a database, see the appendix (the very bottom of
this file).

Note: The config file is read by all three Orthograph tools. Especially the
mandatory part of the file is important as it contains settings for the database
interaction. Without these settings none of the programs will work.


## 3. Create the tables. Make the orthograph_manager script executable and use it:

	$ chmod +x orthograph-manager
	$ ./orthograph-manager -create

The `-create` switch tells the script to setup the database structure for
Orthograph.  It will create a number of tables, all of which start with the
prefix `orthograph_` (or whatever prefix you chose in the config file). 

At this point, if you use the SQLite backend, the SQLite database file is
created at the location you specified in the config file.

## 4. Upload your ortholog set into the database:

	$ ./orthograph-manager FASTAFILE

You will be asked for information about the ortholog set you are loading. If
you made a mistake during input of the information, you may cancel the process
at any time using `Ctrl+C`. I'm sorry if you mistyped the last taxon name and have
to start over :)

The fasta file must have an OrthoDB-style header format as in the following
example:

	>AAEGY:m0cp83 AAEL005334 EOG5000ZK AAEL005334-PA [foo bar baz]

That is, there must exist five space-separated fields, the last one of which may
contain whitespace as well. This is output by [OrthoDB] [3] by default, so you
don't have to worry about that if you downloaded your ortholog set from OrthoDB.
However, dependent on your OrthoDB query, you may need to filter your file so
that it contains only the taxa you want in the ortholog set. A filter script is
provided upon request.  If you didn't get your data from OrthoDB, read `perldoc
orthograph_manager` for further information. Make a note of your ortholog set
name. You will need it later.

To check what sets have been uploaded so far, call `orthograph-manager -ls`. 


## 5. Load proteome sequences into the database :

	$ ./orthograph-manager -load-ogs-peptide FASTAFILE

You need to load data for every taxon separately (this may change in the
future), and you should load data for as many taxa in the orthologs file as
possible. You will be asked for information about the file you are loading.
These sequences are used for the reciprocal BLAST databases. If you don't load
any peptide data, your analysis will be flawed. 

Some of the protein IDs (in the first header field of the OGS file) must
correspond to the fourth header field in the OrthoDB file. This is important,
as these are regarded as part of the ortholog groups. Repeat this step for as
many taxa in your ortholog set as you have peptide sequences for.

If you made a mistake during input of the information, you may cancel the
process at any time using `Ctrl+C`. To check what OGS are present in the
database, call `orthograph-manager -lo`.

If you had attempted this step previously and canceled it mid-process, it may
be that there are remnants of those attempts in the database when you try it
again. You will be notified of this with "Sequence already present in database"
messages.

Yes, I know. OGS loading is slow. I'm working on improving that performance. For
now, be happy that you only need to do this once.

There are options to specify OGS taxon and version so you can easily automate
the process:

	-ogs-version VERSION
	-reference-taxon-shorthand TAXON

The version can be an arbitrary string (but enclose it in quotes if it contains
spaces). The shorthand must be a shorthand that is present in the ortholog set
file (and therefore in the database), just like you would enter it at the
prompt; otherwise, the taxon cannot be correlated.


## 6. Optional: Load nucleotide sequence data into the database:

	$ ./orthograph-manager -load-ogs-nucleotide FASTAFILE

The nucleotide sequences are expected to be the coding sequences for the
peptide sequences you loaded earlier. The headers have to correspond EXACTLY,
or they cannot be correlated and nucleotide output is not possible. For
example, these two headers are not equal, even though they look similar:

	>AAEL1307285-PA Q0C738 Bystin IPR007955
	>AAEL1307285-RA Q0C738 Bystin IPR007955

Make sure the nucleotide sequences can be correlated to the proteome sequences
by giving identical names to corresponding sequences.

And again, I know. OGS loading is slow. I'm working on improving that
performance. For now, be happy that you only need to do this once.

The same options for specifying OGS taxon and version number (see step 5) are
available for nucleotide data, as well.


## 7. Create the required database structure for the Orthograph search program.

Make orthograph-analyzer executable and run it with the -prepare option:

	$ chmod +x orthograph-analyzer
	$ ./orthograph-analyzer -prepare

At this point, if you use the SQLite backend, a species-specific SQLite database
file is created in the output directory you specified in the config file.


## 8. Complete your config file if you didn't fill out everything before.

Supply the rest of the mandatory settings and consider changing some optional
ones that will affect the searches.

## 9. Start Orthograph! 

	$ ./orthograph-analyzer


## 10. Get some coffee, sit back and watch (or do something else).

Orthograph generates the profile hidden Markov models (pHMMs) for your ortholog
set, if they don't exist. This may take a long time depending on the size of
your set, but rest assured, once the pHMMs exist, subsequent analyses will be
faster by that amount of time. 

After that, your input file is translated into all six possible reading frames.
The translated file is placed in your output directory. This library is searched
using all pHMMs. Candidate orthologs are verified with a reciprocal search
against the BLAST database of all proteomes in your ortholog set. The results
are cached in the database.

The HMMER and BLAST output tables are placed in the 'hmmsearch' and 'blastp'
subdirectories in the output directory. The 'aa' and 'nt' directories are
created but left empty. A log file called 'orthograph-DATE.log' is created in
the 'log' directory. 

## 11. Start the reporter

Make orthograph-reporter executable and run it:

  $ chmod +x orthograph-reporter
  $ ./orthograph-reporter

Orthograph-reporter fetches the search results from the database and assigns
ortholog relationships by triangulating reciprocal best hits. After
orthograph-reporter is finished, the output directory contains five
subdirectories:

a) hmmsearch. This contains all the HMMsearch output tables. 

b) blastp. This contains all the BLASTP output tables.

c) aa. This contains the actual result of your analysis. The hit sequences are
output along with the core-ortholog sequences from your ortholog set, grouped
by ortholog groups.

d) nt. This contains the actual results on nucleotide level.

e) log. This contains log files, such as the entire standard output and the
report after running orthograph-reporter.

## 11. ???

## 12. Profit!


APPENDIX
========

MySQL performance
-----------------

Orthograph makes extensive use of MySQL query caching. For optimal performance,
make sure that query caching is enabled in your MySQL instance. Also, if you
plan to run multiple orthograph instances on the same database, you should
definitely use table files instead of database files (`innodb_file_per_table`)
and increase the lock wait timeout (`innodb_lock_wait_timeout`) to between 200
and 600 to make sure that long queries (which may occur) do not block other
orthograph processes.

Required Perl modules
---------------------
Orthograph uses only modules that are present in any standard Perl distribution. 
If you get an error like "Can't locate Some/Thing.pm in @INC" it means that
Perl can't find one of the required modules. Update your Perl installation if
this is the case and make sure it contains these modules:

-  autodie
-  strict
-  warnings
-  Archive::Tar
-  Benchmark 
-  Carp
-  Config
-  DBD::mysql
-  DBD::SQLite
-  DBI
-  Data::Dumper
-  Digest::SHA
-  File::Basename
-  File::Path
-  File::Spec
-  File::Temp
-  FindBin
-  Getopt::Long
-  IO::Dir
-  IO::File
-  List::Util 
-  Time::HiRes

Part of my Diploma thesis at the ZFMK/zmb, Bonn, Germany 
(c) 2011-2012 Malte Petersen <mptrsen@uni-bonn.de>

[1]: <http://cpansearch.perl.org/src/JWIED/DBD-mysql-2.1028/INSTALL.html#special%20systems>
[2]: <http://forums.mysql.com/read.php?51,389833,389833>
[3]: <http://cegg.unige.ch/orthodb5>

## Set up the database. 

Skip this step if you already have a MySQL account and a database (and know
what your credentials are).

	mysql> SOME STATEMENT;

This means you should enter SOME STATEMENT at the MySQL prompt. The `mysql>` is
not part of the statement, but the semicolon is.

There must exist a database for your usage and a database user must have the
usual permissions on it. If you are the administrator of your local machine and
installed MySQL yourself, you have those privileges. However, you should never
do ordinary work as root (the administrator), so let's create a working user.
Login to MySQL as root:

	$ mysql -u root -p
	Enter password:

Enter the MySQL administrator password. You will be greeted by MySQL and then
given a new prompt. Issue the following statement:

	mysql> CREATE USER 'USERNAME'@'localhost' IDENTIFIED BY 'PASSWORD';

Substitute USERNAME and PASSWORD with your username and password of choice. The
single quotes are important. Next, you will create a database and grant the
working user the necessary permissions on it:

	mysql> CREATE DATABASE orthograph;
	mysql> GRANT ALL ON orthograph.* TO 'USERNAME'@'localhost';

You may use a different database name, of course. Make a note of your new user
name, the password and the database name. You will need it later.

Common problems
---------------

"No sequences found. Something went wrong. Check your input file. Exiting." 

Really, check your input file. Is it empty? Is it a valid fasta file? If it
looks ok, try deleting the translated version so Orthograph is forced to
recreate it. 

Options
-------

Orthograph accepts a number of options, both on the command line and in the
config file. In fact, you can customize just about anything. They will be
listed here.

  -c, CONFIGFILE

You can specify the path to a different config file than the default
(orthograph.conf). Orthograph will read its settings from that file. This is
particularly useful when you have a lot of datasets to run Orthograph on.

  --cog-list-file LISTFILE

If you are only interested in a few genes from your ortholog set, you can 
provide Orthograph with a list of ortholog IDs in a file. The IDs must be
in a single line each, and there must be no empty lines in the file. 

	-v, --verbose

Turns on verbose output. Useful if you're not only interested in the progress,
but also in what Orthograph is thinking during its analyses.

	-q, --quiet

Turns off all non-essential output. Useful if you don't want to be bothered
during an Orthograph analysis.

	-d, --debug

Turns on debug output. Even more output, including database queries and
internal workings. This is only helpful if you want to find errors in the
program. Be aware that the log files can become several gigabytes in size this
way.
